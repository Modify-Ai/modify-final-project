import logging
from typing import List, Dict, Any, Optional, Tuple
from PIL import Image, ImageDraw
import numpy as np
import torch
import torch.nn as nn

logger = logging.getLogger(__name__)

class YOLOFashionDetector:
    """
    YOLO ê¸°ë°˜ íŒ¨ì…˜ ì•„ì´í…œ ê°ì§€ê¸°
    - YOLOv8ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ëŒ/ì˜ë¥˜ ì˜ì—­ ê°ì§€
    - ìƒì˜/í•˜ì˜ ì˜ì—­ ë¶„ë¦¬ ì§€ì›
    """
    
    def __init__(self):
        self.model = None
        self.pose_model = None
        self.seg_model = None       # [ì¶”ê°€] ì„¸ê·¸ë©˜í…Œì´ì…˜ìš© (ê°€ìƒ í”¼íŒ…)
        self.initialized = False
        
        # COCO í´ë˜ìŠ¤ ID (person = 0)
        self.PERSON_CLASS_ID = 0
        
        # ìƒì˜/í•˜ì˜ ë¹„ìœ¨ (ì „ì²´ ì‚¬ëŒ bbox ê¸°ì¤€)
        self.UPPER_RATIO = 0.55  # ìƒìœ„ 55%ê°€ ìƒì˜
        self.LOWER_RATIO = 0.45  # í•˜ìœ„ 45%ê°€ í•˜ì˜
        
    def initialize(self):
        """YOLO ëª¨ë¸ ë¡œë“œ"""
        if self.initialized: return True
        try:
            from ultralytics import YOLO
            
            # [ë³´ì•ˆ íŒ¨ì¹˜] PyTorch Safe Globals ë“±ë¡
            try:
                from ultralytics.nn.tasks import DetectionModel
                safe_classes = [
                    DetectionModel,
                    nn.Sequential, nn.Conv2d, nn.BatchNorm2d, nn.SiLU, 
                    nn.Upsample, nn.MaxPool2d, nn.ModuleList,
                ]
                torch.serialization.add_safe_globals(safe_classes)
            except: pass

            # [ë³´ì•ˆ íŒ¨ì¹˜] weights_only=False ê°•ì œ ì ìš© (ë¡œë”© ì‹œì—ë§Œ)
            _original_load = torch.load
            def _unsafe_load(*args, **kwargs):
                if 'weights_only' not in kwargs: kwargs['weights_only'] = False
                return _original_load(*args, **kwargs)
            torch.load = _unsafe_load

            self.model = YOLO('yolov8n.pt')
            try:
                self.pose_model = YOLO('yolov8n-pose.pt')
                logger.info("âœ… YOLO Pose model loaded")
            except: self.pose_model = None
            try:
                self.seg_model = YOLO('yolov8n-seg.pt')
                logger.info("âœ… YOLO Segmentation model loaded")
            except: self.pose_model = None
            
            # ë³µêµ¬
            torch.load = _original_load
            
            self.initialized = True
            logger.info("âœ… YOLO Fashion Detector initialized")
            return True
            
        except ImportError:
            logger.error("âŒ ultralytics not installed.")
            return False
        except Exception as e:
            logger.error(f"âŒ YOLO initialization failed: {e}")
            return False
    
    def detect_person(self, image: Image.Image) -> List[Dict[str, Any]]:
        """
        ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒ ê°ì§€
        """
        if not self.initialized:
            if not self.initialize(): return []
        
        try:
            # ğŸš¨ [FIX] 4ì±„ë„(RGBA) ì´ë¯¸ì§€ê°€ ë“¤ì–´ì˜¤ë©´ 3ì±„ë„(RGB)ë¡œ ë³€í™˜
            if image.mode != 'RGB':
                image = image.convert('RGB')

            # PIL -> numpy
            img_array = np.array(image)
            
            # YOLO ì¶”ë¡ 
            results = self.model(img_array, classes=[self.PERSON_CLASS_ID], verbose=False)
            
            persons = []
            for result in results:
                if result.boxes is None: continue
                for box in result.boxes:
                    x1, y1, x2, y2 = box.xyxy[0].tolist()
                    conf = float(box.conf[0])
                    area = (x2 - x1) * (y2 - y1)
                    
                    persons.append({
                        "bbox": (int(x1), int(y1), int(x2), int(y2)),
                        "confidence": conf,
                        "area": area
                    })
            
            persons.sort(key=lambda x: x["area"], reverse=True)
            return persons
            
        except Exception as e:
            logger.error(f"âŒ Person detection failed: {e}")
            return []
    
    def get_keypoints(self, image: Image.Image) -> Optional[Dict[str, Tuple[int, int]]]:
        if self.pose_model is None: return None
        try:
            # ğŸš¨ [FIX] í¬ì¦ˆ ì¶”ì • ì‹œì—ë„ RGB ë³€í™˜ í™•ì¸
            if image.mode != 'RGB':
                image = image.convert('RGB')
                
            img_array = np.array(image)
            results = self.pose_model(img_array, verbose=False)
            
            KEYPOINT_NAMES = {5: "left_shoulder", 6: "right_shoulder", 11: "left_hip", 12: "right_hip"}
            for result in results:
                if result.keypoints is None: continue
                keypoints = result.keypoints.xy[0].tolist()
                kp_dict = {}
                for idx, name in KEYPOINT_NAMES.items():
                    if idx < len(keypoints):
                        x, y = keypoints[idx]
                        if x > 0 and y > 0: kp_dict[name] = (int(x), int(y))
                if kp_dict: return kp_dict
            return None
        except: return None
    
    def _crop_from_bbox(self, image: Image.Image, bbox: Tuple[int,int,int,int], target: str) -> Image.Image:
        x1, y1, x2, y2 = bbox
        w, h = image.size
        
        # Padding
        px = int((x2 - x1) * 0.1)
        py = int((y2 - y1) * 0.05)
        
        x1 = max(0, x1 - px)
        y1 = max(0, y1 - py)
        x2 = min(w, x2 + px)
        y2 = min(h, y2 + py)
        
        crop_box = (x1, y1, x2, y2)
        if target == "upper":
             crop_box = (x1, y1, x2, int(y1 + (y2-y1) * self.UPPER_RATIO))
        elif target == "lower":
             crop_box = (x1, int(y1 + (y2-y1) * (1 - self.LOWER_RATIO)), x2, y2)
             
        return image.crop(crop_box)

    def crop_fashion_regions(self, image: Image.Image, target: str = "full") -> Optional[Image.Image]:
        persons = self.detect_person(image)
        if not persons: return image
        return self._crop_from_bbox(image, persons[0]["bbox"], target)
    
    def extract_fashion_features(self, image: Image.Image) -> Dict[str, Optional[Image.Image]]:
        result = {"full": None, "upper": None, "lower": None}
        
        persons = self.detect_person(image)
        if not persons:
            result["full"] = image 
            return result
            
        main_bbox = persons[0]["bbox"]
        
        # ì›ë³¸ ì´ë¯¸ì§€ê°€ RGBAë¼ë©´ ì—¬ê¸°ì„œë„ ë³€í™˜ëœ ë²„ì „ì„ ì‚¬ìš©í•˜ëŠ” ê²Œ ì•ˆì „í•˜ì§€ë§Œ,
        # cropì€ ëª¨ë“œ ìƒê´€ì—†ì´ ë™ì‘í•˜ë¯€ë¡œ ê´œì°®ìŠµë‹ˆë‹¤.
        # ë‹¤ë§Œ detect_person ë‚´ë¶€ì—ì„œ ë³€í™˜ëœ ì´ë¯¸ì§€ë¥¼ ë¦¬í„´í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 
        # ì›ë³¸ imageë¥¼ ê·¸ëŒ€ë¡œ ì”ë‹ˆë‹¤.
        
        result["full"] = self._crop_from_bbox(image, main_bbox, "full")
        result["upper"] = self._crop_from_bbox(image, main_bbox, "upper")
        result["lower"] = self._crop_from_bbox(image, main_bbox, "lower")
        
        return result
    
    # [ì¶”ê°€] ê°€ìƒ í”¼íŒ…ìš© ë§ˆìŠ¤í¬ ìƒì„± í•¨ìˆ˜
    def generate_mask_for_fitting(self, image: Image.Image, target: str = "upper") -> Optional[Image.Image]:
        """
        YOLO Pose ê¸°ë°˜ì˜ ì •ë°€ ë§ˆìŠ¤í‚¹
        - ì–¼êµ´ ë³´í˜¸: Bounding Box ìƒë‹¨ 13% ì œì™¸
        - ìƒ/í•˜ì˜ ë¶„ë¦¬: ê³¨ë°˜(Hip) ì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë™ì  ë¶„ë¦¬
        """
        if not self.initialized: self.initialize()
        if self.seg_model is None or self.pose_model is None: 
            return None

        try:
            if image.mode != "RGB": image = image.convert("RGB")
            w, h = image.size

            # 1. Segmentation ì¶”ë¡  (ì‚¬ëŒ ëª¨ì–‘ ë”°ê¸°)
            seg_results = self.seg_model(image, classes=[0], verbose=False) # 0: Person

            final_mask = None
            person_box = None   # ì‚¬ëŒ ìœ„ì¹˜(ë°•ìŠ¤) ì €ì¥ìš©

            # ê°€ì¥ í° ì‚¬ëŒ(ì£¼ì¸ê³µ)ì˜ ë§ˆìŠ¤í¬ ì°¾ê¸°
            if seg_results and seg_results[0].masks:
                # ë©´ì ì´ ê°€ì¥ í° ì‚¬ëŒ ì„ íƒ
                masks = seg_results[0].masks.data.cpu().numpy()
                boxes = seg_results[0].boxes.xyxy.cpu().numpy()
                
                # (ì—¬ëŸ¬ ëª…ì¼ ê²½ìš° ê°€ì¥ ì¤‘ì•™ì— ìˆê±°ë‚˜ í° ì‚¬ëŒì„ ì°¾ëŠ” ë¡œì§ì´ ì¢‹ìœ¼ë‚˜, ì—¬ê¸°ì„  ì²« ë²ˆì§¸ ê°ì§€ëœ ê°ì²´ ì‚¬ìš©)
                # ë³´í†µ YOLOëŠ” confidence ìˆœìœ¼ë¡œ ì •ë ¬ë˜ì–´ ìˆìŒ
                mask_tensor = masks[0]
                person_box = boxes[0] # x1, y1, x2, y2

                # ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì§• (YOLO ë§ˆìŠ¤í¬ -> ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°)
                final_mask = Image.fromarray((mask_tensor * 255).astype(np.uint8)).resize((w, h))
            
            if final_mask is None: return None

            draw = ImageDraw.Draw(final_mask)

            # 2. Pose ì¶”ë¡  (ê´€ì ˆ ìœ„ì¹˜ ì°¾ê¸°)
            pose_results = self.pose_model(image, verbose=False)

            # ê³¨ë°˜(Hip) ìœ„ì¹˜ ì°¾ê¸° (Keypoint Index : 11=Left Hip, 12=Right Hip)
            hip_y = int(h * 0.6)    # ê¸°ë³¸ê°’ : ëª» ì°¾ìœ¼ë©´ 60% ì§€ì  (Fallback)

            if pose_results and pose_results[0].keypoints is not None:
                # xy ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
                keypoints = pose_results[0].keypoints.xy.cpu().numpy()[0]
                
                # 11ë²ˆ(ì™¼ìª½ ê³¨ë°˜), 12ë²ˆ(ì˜¤ë¥¸ìª½ ê³¨ë°˜)ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                # ì¢Œí‘œê°€ (0,0)ì´ë©´ ê°ì§€ ì•ˆ ëœ ê²ƒ
                left_hip = keypoints[11]
                right_hip = keypoints[12]
                
                hips = []
                if left_hip[1] > 0: hips.append(left_hip[1])
                if right_hip[1] > 0: hips.append(right_hip[1])
                
                if hips:
                    # ë‘ ê³¨ë°˜ì˜ í‰ê·  ë†’ì´ë¥¼ í—ˆë¦¬ì„ ìœ¼ë¡œ ì¡ìŒ + ì•½ê°„ì˜ ì—¬ìœ (10px)
                    hip_y = int(sum(hips) / len(hips)) + 10
                else:
                    # ê³¨ë°˜ì´ ì•ˆ ë³´ì¸ë‹¤? = ìƒë°˜ì‹  í´ë¡œì¦ˆì—… ì‚¬ì§„ì¼ í™•ë¥  ë†’ìŒ
                    # ì´ ê²½ìš° í•˜ë‹¨ë¶€ë¥¼ ìë¥´ì§€ ì•Šê³  ëê¹Œì§€(100%) ì˜·ìœ¼ë¡œ ê°„ì£¼
                    hip_y = h
            
            # ---------------------------------------------------------
            # ğŸ¨ ë§ˆìŠ¤í‚¹ ê·¸ë¦¬ê¸° (ê²€ì€ìƒ‰=ë³´í˜¸ / í°ìƒ‰=ë³€ê²½)
            # ---------------------------------------------------------
            
            # A. ë¨¸ë¦¬ ë³´í˜¸ ë¡œì§
            # ì½”(Nose)ì™€ ì–´ê¹¨(Shoulder) ì‚¬ì´ì˜ ëª© ì°¾ê¸°
            head_limit = 0  # ê¸°ë³¸ê°’

            if pose_results and pose_results[0].keypoints is not None:
                keypoints = pose_results[0].keypoints.xy.cpu().numpy()[0]
                
                # Keypoint Index: 0=ì½”, 5=ì™¼ìª½ ì–´ê¹¨, 6=ì˜¤ë¥¸ìª½ ì–´ê¹¨
                nose = keypoints[0]
                left_shoulder = keypoints[5]
                right_shoulder = keypoints[6]
                
                # 1. ì–´ê¹¨ ë†’ì´ í‰ê·  ê³„ì‚°
                shoulder_y = 0
                if left_shoulder[1] > 0 and right_shoulder[1] > 0:
                    shoulder_y = (left_shoulder[1] + right_shoulder[1]) / 2
                elif left_shoulder[1] > 0: shoulder_y = left_shoulder[1]
                elif right_shoulder[1] > 0: shoulder_y = right_shoulder[1]
                
                # 2. ì½”(Nose) ì¢Œí‘œê°€ ìˆìœ¼ë©´ -> "ì½”ì™€ ì–´ê¹¨ì˜ ì •ì¤‘ì•™"ì„ ìë¥´ëŠ” ì„ ìœ¼ë¡œ ì„¤ì •
                if nose[1] > 0 and shoulder_y > 0:
                    # ì½”ì™€ ì–´ê¹¨ ì‚¬ì´(ëª©)ì˜ ì¤‘ê°„ ì§€ì 
                    head_limit = (nose[1] + shoulder_y) / 2
                    
                # 3. ì½”ë¥¼ ëª» ì°¾ì•˜ìœ¼ë©´(ë’·ëª¨ìŠµ ë“±) -> ì–´ê¹¨ ë„ˆë¹„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¹„ë¡€í•´ì„œ ìœ„ë¡œ ì˜¬ë¦¼
                elif shoulder_y > 0:
                    # ì–´ê¹¨ ë„ˆë¹„ ê³„ì‚° (ì¢Œìš° ì–´ê¹¨ê°€ ë‹¤ ìˆì„ ë•Œ)
                    if left_shoulder[0] > 0 and right_shoulder[0] > 0:
                        width = abs(left_shoulder[0] - right_shoulder[0])
                        # ì–´ê¹¨ ë„ˆë¹„ì˜ 50%ë§Œí¼ ìœ„ë¡œ ì˜¬ë¦¬ë©´ ëŒ€ëµ ëª©~ë¨¸ë¦¬ ê²½ê³„
                        head_limit = shoulder_y - (width * 0.5)
                    else:
                        # ì–´ê¹¨ ë„ˆë¹„ë„ ëª¨ë¥´ë©´ ê¸°ì¡´ ë°©ì‹(ë°•ìŠ¤ ê¸°ì¤€) Fallback
                        if person_box is not None:
                            head_limit = person_box[1] + ((person_box[3] - person_box[1]) * 0.13)
            
            # ì•ˆì „ì¥ì¹˜: í˜¹ì‹œ ê³„ì‚°ëœ ë¼ì¸ì´ 0ë³´ë‹¤ ì‘ìœ¼ë©´ 0ìœ¼ë¡œ
            head_limit = max(0, int(head_limit))
            
            # ê²€ì€ìƒ‰ ë³´í˜¸ ì˜ì—­ ê·¸ë¦¬ê¸°
            draw.rectangle([(0, 0), (w, head_limit)], fill=0)

            # B. ìƒì˜/í•˜ì˜ ì˜ì—­ ë¶„ë¦¬ (Pose ê¸°ë°˜)
            if target == "upper":
                # ìƒì˜ í”¼íŒ… -> ê³¨ë°˜(hip_y) ì•„ë˜ìª½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ì¹ í•´ì„œ í•˜ì²´ ë³´í˜¸
                # ë‹¨, hip_yê°€ ì´ë¯¸ì§€ ë(h)ì´ë©´ í•˜ì²´ê°€ ì—†ëŠ” ê²ƒì´ë¯€ë¡œ ì¹ í•˜ì§€ ì•ŠìŒ
                if hip_y < h:
                    draw.rectangle([(0, hip_y), (w, h)], fill=0)

            elif target == "lower":
                # í•˜ì˜ í”¼íŒ… -> ê³¨ë°˜(hip_y) ìœ„ìª½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ì¹ í•´ì„œ ìƒì²´ ë³´í˜¸
                # (ë¨¸ë¦¬ ë³´í˜¸ ë¼ì¸ë³´ë‹¤ëŠ” ì•„ë˜ì—¬ì•¼ í•¨)
                start_y = max(int(head_limit), 0) if person_box is not None else 0
                draw.rectangle([(0, start_y), (w, hip_y)], fill=0)
            elif target == "full":
                # ë“œë ˆìŠ¤/ì „ì‹  -> ë¨¸ë¦¬ë§Œ ë³´í˜¸í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìœ ì§€
                pass
            
            return final_mask
        
        except Exception as e:
            logger.error(f"âŒ Mask generation failed: {e}")
            return None

yolo_detector = YOLOFashionDetector()